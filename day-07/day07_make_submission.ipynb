{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/YAwnPhFpuKoP39SbbEBl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna-gera/my-aiml-learning/blob/main/day-7/day07_make_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWlO9LrJfNQv",
        "outputId": "81324089-dcd9-40d3-bc74-d6974d28f393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using train file: day02/day02_titanic_preserved.csv\n",
            "Using test file: test.csv\n",
            "Train shape: (891, 29) Test shape: (418, 29)\n",
            "Submission saved to: day07/submission.csv\n",
            "All done. Upload submission.csv to Kaggle.\n"
          ]
        }
      ],
      "source": [
        "# day07_make_submission.py\n",
        "# Usage: put train.csv (or day02/day02_titanic_preserved.csv) and test.csv in your project root,\n",
        "# then run: python day07_make_submission.py\n",
        "# Output: day07/submission.csv\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "OUT = Path(\"day07\"); OUT.mkdir(exist_ok=True)\n",
        "ASSETS = OUT / \"assets\"; ASSETS.mkdir(exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# 1) Load data (train + test)\n",
        "# -------------------------\n",
        "# prefer preserved cleaned train (with Name/Cabin). Fallback to train.csv\n",
        "train_paths = [Path(\"day02/day02_titanic_preserved.csv\"), Path(\"day02/train.csv\"), Path(\"train.csv\")]\n",
        "train_path = next((p for p in train_paths if p.exists()), None)\n",
        "if train_path is None:\n",
        "    raise FileNotFoundError(\"train.csv not found. Place train.csv or day02/day02_titanic_preserved.csv in project root.\")\n",
        "test_path = Path(\"test.csv\")\n",
        "if not test_path.exists():\n",
        "    raise FileNotFoundError(\"test.csv not found. Download it from the Kaggle Titanic competition and put test.csv in project root.\")\n",
        "\n",
        "print(\"Using train file:\", train_path)\n",
        "print(\"Using test file:\", test_path)\n",
        "\n",
        "train = pd.read_csv(train_path)\n",
        "test = pd.read_csv(test_path)\n",
        "\n",
        "# Keep PassengerId for submission\n",
        "test_passenger_ids = test['PassengerId'].copy()\n",
        "\n",
        "# -------------------------\n",
        "# 2) Feature engineering function (must match Day5)\n",
        "# -------------------------\n",
        "def feature_engineer(df, age_map=None, is_train=False):\n",
        "    df = df.copy()\n",
        "    # FamilySize, IsAlone\n",
        "    df['FamilySize'] = df.get('SibSp', 0).fillna(0).astype(int) + df.get('Parch', 0).fillna(0).astype(int) + 1\n",
        "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
        "\n",
        "    # Title extraction\n",
        "    if 'Name' in df.columns:\n",
        "        # Extract the title and then strip whitespace, ensuring it's a Series\n",
        "        df['Title'] = df['Name'].str.extract(r',\\s*([^\\.]+)\\.')[0].str.strip()\n",
        "        # replace known variants\n",
        "        df['Title'] = df['Title'].replace({\n",
        "            \"Mlle\":\"Miss\",\"Ms\":\"Miss\",\"Mme\":\"Mrs\",\n",
        "            \"Lady\":\"Rare\",\"Countess\":\"Rare\",\"Sir\":\"Rare\",\"Don\":\"Rare\",\"Dona\":\"Rare\",\n",
        "            \"Col\":\"Rare\",\"Major\":\"Rare\",\"Capt\":\"Rare\",\"Rev\":\"Rare\",\"Dr\":\"Rare\"\n",
        "        })\n",
        "    else:\n",
        "        df['Title'] = 'Unknown'\n",
        "\n",
        "    # collapse very rare titles if train\n",
        "    if is_train:\n",
        "        vc = df['Title'].value_counts()\n",
        "        rare_titles = vc[vc < 10].index.tolist()\n",
        "        df.loc[df['Title'].isin(rare_titles), 'Title'] = 'Rare'\n",
        "    else:\n",
        "        # For test set, any unseen title will remain; we'll handle alignment later\n",
        "        pass\n",
        "\n",
        "    # Deck from Cabin (first letter), missing->U\n",
        "    if 'Cabin' in df.columns:\n",
        "        df['Cabin'] = df['Cabin'].fillna('U')\n",
        "        df['Deck'] = df['Cabin'].astype(str).str[0]\n",
        "    else:\n",
        "        df['Deck'] = 'U'\n",
        "\n",
        "    # Fare per person (handle missing)\n",
        "    df['Fare'] = pd.to_numeric(df['Fare'], errors='coerce')\n",
        "    if df['Fare'].isna().any():\n",
        "        df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
        "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
        "\n",
        "    # Age imputation by Title median (train computes map; test uses it)\n",
        "    df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
        "    if is_train:\n",
        "        age_map = df.groupby('Title')['Age'].median().to_dict()\n",
        "        df['Age'] = df.apply(lambda r: age_map[r['Title']] if pd.isna(r['Age']) and r['Title'] in age_map else r['Age'], axis=1)\n",
        "    else:\n",
        "        if age_map is not None:\n",
        "            # fill using mapping; fallback to overall median\n",
        "            overall_med = np.nanmedian(list(age_map.values()))\n",
        "            df['Age'] = df.apply(lambda r: age_map.get(r['Title'], overall_med) if pd.isna(r['Age']) else r['Age'], axis=1)\n",
        "    # If still missing, fill with median\n",
        "    if df['Age'].isna().any():\n",
        "        df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "\n",
        "    # log fare\n",
        "    df['Fare_log'] = np.log1p(df['Fare'])\n",
        "\n",
        "    # Age bin\n",
        "    df['AgeBin'] = pd.cut(df['Age'], bins=[0,12,20,40,60,120], labels=['Child','Teen','Adult','MidAge','Senior'])\n",
        "\n",
        "    # Sex binary\n",
        "    if 'Sex' in df.columns:\n",
        "        df['Sex_bin'] = (df['Sex'].str.lower().str.startswith('m')).astype(int)\n",
        "    else:\n",
        "        df['Sex_bin'] = 0\n",
        "\n",
        "    return df, (age_map if is_train else None)\n",
        "\n",
        "# Run on train (compute age_map)\n",
        "train_fe, age_map = feature_engineer(train, is_train=True)\n",
        "# Run on test using train's age_map\n",
        "test_fe, _ = feature_engineer(test, age_map=age_map, is_train=False)\n",
        "\n",
        "# -------------------------\n",
        "# 3) Pick features & encode\n",
        "# -------------------------\n",
        "feature_cols = ['Pclass','Sex_bin','Age','Fare_log','FamilySize','FarePerPerson','IsAlone','Title','Deck','Embarked','AgeBin']\n",
        "# keep only existing\n",
        "feature_cols = [c for c in feature_cols if c in train_fe.columns]\n",
        "\n",
        "X_train = train_fe[feature_cols].copy()\n",
        "y_train = train_fe['Survived'].copy()\n",
        "X_test = test_fe[feature_cols].copy()\n",
        "\n",
        "# One-hot encode categorical columns (Title, Deck, Embarked, AgeBin)\n",
        "cat_cols = [c for c in ['Title','Deck','Embarked','AgeBin'] if c in X_train.columns]\n",
        "X_train = pd.get_dummies(X_train, columns=cat_cols, dummy_na=False)\n",
        "X_test = pd.get_dummies(X_test, columns=cat_cols, dummy_na=False)\n",
        "\n",
        "# Align test columns to train columns (add missing columns with 0)\n",
        "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
        "\n",
        "# -------------------------\n",
        "# 4) Train a model (RandomForest baseline)\n",
        "# -------------------------\n",
        "model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Optionally save model & columns for future\n",
        "joblib.dump(model, ASSETS / \"rf_day07.joblib\")\n",
        "pd.Series(X_train.columns).to_csv(ASSETS / \"feature_columns_day07.csv\", index=False)\n",
        "\n",
        "# -------------------------\n",
        "# 5) Predict on test, create submission\n",
        "# -------------------------\n",
        "preds = model.predict(X_test)\n",
        "# ensure int type 0/1\n",
        "preds = preds.astype(int)\n",
        "\n",
        "submission = pd.DataFrame({'PassengerId': test_passenger_ids, 'Survived': preds})\n",
        "submission_path = OUT / \"submission.csv\"\n",
        "submission.to_csv(submission_path, index=False)\n",
        "print(\"Submission saved to:\", submission_path)\n",
        "\n",
        "# Save a quick results note\n",
        "with open(OUT / \"readme.txt\", \"w\") as f:\n",
        "    f.write(\"Day 7: Baseline RF submission\\n\")\n",
        "    f.write(f\"Model: RandomForestClassifier(n_estimators=200)\\n\")\n",
        "    f.write(f\"Features used: {len(X_train.columns)} columns\\n\")\n",
        "    f.write(\"Submission: submission.csv\\n\")\n",
        "print(\"All done. Upload submission.csv to Kaggle.\")"
      ]
    }
  ]
}
