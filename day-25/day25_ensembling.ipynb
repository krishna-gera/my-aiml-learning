{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjku5phKiDxHnzI4NOC9j1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna-gera/my-aiml-learning/blob/main/day-25/day25_ensembling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UPJt_kuFntQ",
        "outputId": "b879e2d4-e1fe-4010-e5c4-a64bfc8e0126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (891, 28) Test shape: (418, 28)\n",
            "X_train_full: (712, 28) X_hold: (179, 28)\n",
            "Numeric cols: ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'IsAlone', 'Fare_log', 'TicketGroupSize']\n",
            "Categorical cols: ['Sex_male', 'Embarked_Q', 'Embarked_S', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare', 'Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F', 'Deck_G', 'Deck_T', 'Deck_U', 'AgeBin_Child', 'AgeBin_MidAge', 'AgeBin_Senior', 'AgeBin_Teen']\n",
            "\n",
            "Generating OOF for base model: rf\n",
            "  Fold 1/5 ...\n",
            "  Fold 2/5 ...\n",
            "  Fold 3/5 ...\n",
            "  Fold 4/5 ...\n",
            "  Fold 5/5 ...\n",
            "\n",
            "Generating OOF for base model: et\n",
            "  Fold 1/5 ...\n",
            "  Fold 2/5 ...\n",
            "  Fold 3/5 ...\n",
            "  Fold 4/5 ...\n",
            "  Fold 5/5 ...\n",
            "\n",
            "Generating OOF for base model: gb\n",
            "  Fold 1/5 ...\n",
            "  Fold 2/5 ...\n",
            "  Fold 3/5 ...\n",
            "  Fold 4/5 ...\n",
            "  Fold 5/5 ...\n",
            "\n",
            "Meta model trained on OOF meta-features.\n",
            "\n",
            "Building holdout meta-features...\n",
            "\n",
            "Holdout evaluation:\n",
            "Accuracy: 0.8101\n",
            "ROC AUC: 0.8264\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.88      0.85       110\n",
            "         1.0       0.79      0.70      0.74        69\n",
            "\n",
            "    accuracy                           0.81       179\n",
            "   macro avg       0.80      0.79      0.79       179\n",
            "weighted avg       0.81      0.81      0.81       179\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[97 13]\n",
            " [21 48]]\n",
            "\n",
            "Refitting preprocessor on FULL training data and building final meta-features...\n",
            "\n",
            "Generating OOF for base model: rf\n",
            "  Fold 1/5 ...\n",
            "  Fold 2/5 ...\n",
            "  Fold 3/5 ...\n",
            "  Fold 4/5 ...\n",
            "  Fold 5/5 ...\n",
            "\n",
            "Generating OOF for base model: et\n",
            "  Fold 1/5 ...\n",
            "  Fold 2/5 ...\n",
            "  Fold 3/5 ...\n",
            "  Fold 4/5 ...\n",
            "  Fold 5/5 ...\n",
            "\n",
            "Generating OOF for base model: gb\n",
            "  Fold 1/5 ...\n",
            "  Fold 2/5 ...\n",
            "  Fold 3/5 ...\n",
            "  Fold 4/5 ...\n",
            "  Fold 5/5 ...\n",
            "\n",
            "Retraining base models on FULL training data for saving...\n",
            "Saved models & preprocessor to: day25_models.joblib\n",
            "Saved submission to: day25_submission.csv\n",
            "Saved report to: day25_report.json\n",
            "\n",
            "Done ✅\n"
          ]
        }
      ],
      "source": [
        "# day25_ensembling.py\n",
        "\"\"\"\n",
        "Day 25 - Ensembling (Stacking / Blending) using OOF predictions\n",
        "Inputs:\n",
        "    - train_processed.csv (must contain 'Survived' target)\n",
        "    - test_processed.csv  (must contain PassengerId/Id)\n",
        "Outputs:\n",
        "    - day25_submission.csv\n",
        "    - day25_models.joblib\n",
        "    - day25_report.json\n",
        "\"\"\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib, json\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "from sklearn.base import clone\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TRAIN_FILE = \"train_processed.csv\"\n",
        "TEST_FILE = \"test_processed.csv\"\n",
        "TARGET = \"Survived\"\n",
        "REPORT_FILE = \"day25_report.json\"\n",
        "MODELS_FILE = \"day25_models.joblib\"\n",
        "SUBMISSION_FILE = \"day25_submission.csv\"\n",
        "\n",
        "def find_id_column(df):\n",
        "    for c in [\"PassengerId\", \"Id\", \"ID\", \"passengerid\"]:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def build_preprocessor(X):\n",
        "    numeric_cols = X.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
        "    categorical_cols = X.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
        "    boolean_cols = X.select_dtypes(include=[\"bool\"]).columns.tolist()\n",
        "\n",
        "    # numeric pipeline\n",
        "    num_pipe = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "\n",
        "    transformers = [(\"num\", num_pipe, numeric_cols)]\n",
        "\n",
        "    # categorical pipeline (only if categories exist)\n",
        "    if categorical_cols:\n",
        "        cat_pipe = Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "        ])\n",
        "        transformers.append((\"cat\", cat_pipe, categorical_cols))\n",
        "\n",
        "    # boolean pipeline (only if booleans exist)\n",
        "    if boolean_cols:\n",
        "        bool_pipe = Pipeline([\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "        ])\n",
        "        transformers.append((\"bool\", bool_pipe, boolean_cols))\n",
        "\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=transformers,\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "\n",
        "    return preprocessor, numeric_cols, categorical_cols + boolean_cols\n",
        "\n",
        "\n",
        "def get_oof_predictions(base_models, X, y, X_test, n_splits=5):\n",
        "    \"\"\"\n",
        "    For each base model, produce out-of-fold train predictions and averaged test predictions.\n",
        "    Returns:\n",
        "        meta_train: (n_samples, n_models)\n",
        "        meta_test:  (n_test, n_models)\n",
        "    \"\"\"\n",
        "    n_models = len(base_models)\n",
        "    n_samples = X.shape[0]\n",
        "    n_test = X_test.shape[0]\n",
        "    meta_train = np.zeros((n_samples, n_models))\n",
        "    meta_test = np.zeros((n_test, n_models))\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "    for i, (name, model) in enumerate(base_models):\n",
        "        print(f\"\\nGenerating OOF for base model: {name}\")\n",
        "        oof_train = np.zeros(n_samples)\n",
        "        test_fold_preds = np.zeros((n_test, n_splits))\n",
        "\n",
        "        for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "            print(f\"  Fold {fold+1}/{n_splits} ...\")\n",
        "            m = clone(model)\n",
        "            m.fit(X[tr_idx], y.iloc[tr_idx])\n",
        "            # predict_proba for binary class -> prob of class 1\n",
        "            oof_train[val_idx] = m.predict_proba(X[val_idx])[:, 1]\n",
        "            test_fold_preds[:, fold] = m.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        meta_train[:, i] = oof_train\n",
        "        meta_test[:, i] = test_fold_preds.mean(axis=1)\n",
        "\n",
        "    return meta_train, meta_test\n",
        "\n",
        "def main():\n",
        "    # ---------------------------\n",
        "    # Step 1: Load\n",
        "    # ---------------------------\n",
        "    train = pd.read_csv(TRAIN_FILE)\n",
        "    test = pd.read_csv(TEST_FILE)\n",
        "    id_col = find_id_column(test)\n",
        "\n",
        "    if TARGET not in train.columns:\n",
        "        raise ValueError(f\"Target column '{TARGET}' not found in {TRAIN_FILE}\")\n",
        "\n",
        "    drop_cols = [TARGET]\n",
        "    if id_col and id_col in train.columns:\n",
        "        drop_cols.append(id_col)\n",
        "\n",
        "    X = train.drop(columns=drop_cols, errors=\"ignore\")\n",
        "    y = train[TARGET].copy()\n",
        "\n",
        "    test_ids = test[id_col].copy() if id_col else pd.Series(np.arange(len(test)), name=\"Id\")\n",
        "    X_test_full = test.drop(columns=[id_col], errors=\"ignore\")\n",
        "\n",
        "    print(\"Train shape:\", X.shape, \"Test shape:\", X_test_full.shape)\n",
        "\n",
        "    # ---------------------------\n",
        "    # Step 2: Holdout split for honest evaluation\n",
        "    # ---------------------------\n",
        "    X_train_full, X_hold, y_train_full, y_hold = train_test_split(\n",
        "        X, y, test_size=0.20, random_state=RANDOM_STATE, stratify=y\n",
        "    )\n",
        "    print(\"X_train_full:\", X_train_full.shape, \"X_hold:\", X_hold.shape)\n",
        "\n",
        "    # ---------------------------\n",
        "    # Step 3: Preprocessing (fit on X_train_full only)\n",
        "    # ---------------------------\n",
        "    preprocessor, numeric_cols, categorical_cols = build_preprocessor(X_train_full)\n",
        "    print(\"Numeric cols:\", numeric_cols)\n",
        "    print(\"Categorical cols:\", categorical_cols)\n",
        "\n",
        "    X_train_proc = preprocessor.fit_transform(X_train_full)\n",
        "    X_hold_proc = preprocessor.transform(X_hold)\n",
        "    X_test_proc = preprocessor.transform(X_test_full)\n",
        "\n",
        "    # ---------------------------\n",
        "    # Step 4: Base models definition\n",
        "    # ---------------------------\n",
        "    base_models = [\n",
        "        (\"rf\", RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=RANDOM_STATE)),\n",
        "        (\"et\", ExtraTreesClassifier(n_estimators=200, n_jobs=-1, random_state=RANDOM_STATE)),\n",
        "        (\"gb\", GradientBoostingClassifier(n_estimators=200, random_state=RANDOM_STATE))\n",
        "    ]\n",
        "\n",
        "    # ---------------------------\n",
        "    # Step 5: OOF on X_train_full (to train meta model)\n",
        "    # ---------------------------\n",
        "    meta_train, meta_test_approx = get_oof_predictions(base_models, X_train_proc, y_train_full, X_test_proc, n_splits=5)\n",
        "\n",
        "    # ---------------------------\n",
        "    # Step 6: Train meta model\n",
        "    # ---------------------------\n",
        "    meta_clf = LogisticRegression(max_iter=2000, random_state=RANDOM_STATE)\n",
        "    meta_clf.fit(meta_train, y_train_full)\n",
        "    print(\"\\nMeta model trained on OOF meta-features.\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # Step 7: Evaluate on holdout\n",
        "    #    Build holdout meta features by training base models on full X_train_full and predicting on X_hold\n",
        "    # ---------------------------\n",
        "    print(\"\\nBuilding holdout meta-features...\")\n",
        "    meta_hold = np.zeros((X_hold_proc.shape[0], len(base_models)))\n",
        "    for i, (name, model) in enumerate(base_models):\n",
        "        m = clone(model)\n",
        "        m.fit(X_train_proc, y_train_full)   # train on full 'train' part\n",
        "        meta_hold[:, i] = m.predict_proba(X_hold_proc)[:, 1]\n",
        "\n",
        "    y_hold_pred = meta_clf.predict(meta_hold)\n",
        "    try:\n",
        "        y_hold_proba = meta_clf.predict_proba(meta_hold)[:, 1]\n",
        "    except Exception:\n",
        "        y_hold_proba = None\n",
        "\n",
        "    acc_hold = accuracy_score(y_hold, y_hold_pred)\n",
        "    roc_hold = roc_auc_score(y_hold, y_hold_proba) if y_hold_proba is not None else None\n",
        "    cr_hold = classification_report(y_hold, y_hold_pred)\n",
        "    cm_hold = confusion_matrix(y_hold, y_hold_pred)\n",
        "\n",
        "    print(\"\\nHoldout evaluation:\")\n",
        "    print(f\"Accuracy: {acc_hold:.4f}\")\n",
        "    if roc_hold is not None:\n",
        "        print(f\"ROC AUC: {roc_hold:.4f}\")\n",
        "    print(\"\\nClassification report:\\n\", cr_hold)\n",
        "    print(\"\\nConfusion matrix:\\n\", cm_hold)\n",
        "\n",
        "    # ---------------------------\n",
        "    # Step 8: Final re-fit on full training set for submission\n",
        "    #    - Refit preprocessor on FULL training X (X_train_full + X_hold)\n",
        "    #    - Generate OOF meta-features on FULL training & test\n",
        "    #    - Train final meta on those OOF features\n",
        "    # ---------------------------\n",
        "    print(\"\\nRefitting preprocessor on FULL training data and building final meta-features...\")\n",
        "    X_full = pd.concat([X_train_full, X_hold], axis=0).reset_index(drop=True)\n",
        "    y_full = pd.concat([y_train_full, y_hold], axis=0).reset_index(drop=True)\n",
        "\n",
        "    preprocessor_full, _, _ = build_preprocessor(X_full)\n",
        "    X_full_proc = preprocessor_full.fit_transform(X_full)\n",
        "    X_test_proc_full = preprocessor_full.transform(X_test_full)\n",
        "\n",
        "    meta_train_full, meta_test_final = get_oof_predictions(base_models, X_full_proc, y_full, X_test_proc_full, n_splits=5)\n",
        "\n",
        "    final_meta_clf = LogisticRegression(max_iter=2000, random_state=RANDOM_STATE)\n",
        "    final_meta_clf.fit(meta_train_full, y_full)\n",
        "\n",
        "    final_test_probs = final_meta_clf.predict_proba(meta_test_final)[:, 1]\n",
        "    final_test_preds = (final_test_probs >= 0.5).astype(int)\n",
        "\n",
        "    # ---------------------------\n",
        "    # Step 9: Save models (base models trained on FULL), meta model & preprocessor\n",
        "    # ---------------------------\n",
        "    print(\"\\nRetraining base models on FULL training data for saving...\")\n",
        "    fitted_base_models = {}\n",
        "    for name, model in base_models:\n",
        "        m = clone(model)\n",
        "        m.fit(X_full_proc, y_full)\n",
        "        fitted_base_models[name] = m\n",
        "\n",
        "    saved_objects = {\n",
        "        \"preprocessor\": preprocessor_full,\n",
        "        \"base_models\": fitted_base_models,\n",
        "        \"meta_model\": final_meta_clf,\n",
        "        \"meta_model_trained_on\": \"OOF on full training\"\n",
        "    }\n",
        "    joblib.dump(saved_objects, MODELS_FILE)\n",
        "    print(f\"Saved models & preprocessor to: {MODELS_FILE}\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # Step 10: Save submission & report\n",
        "    # ---------------------------\n",
        "    submission = pd.DataFrame({\n",
        "        id_col if id_col else \"Id\": test_ids,\n",
        "        TARGET: final_test_preds\n",
        "    })\n",
        "    submission.to_csv(SUBMISSION_FILE, index=False)\n",
        "    print(f\"Saved submission to: {SUBMISSION_FILE}\")\n",
        "\n",
        "    report = {\n",
        "        \"holdout_metrics\": {\n",
        "            \"accuracy\": float(acc_hold),\n",
        "            \"roc_auc\": float(roc_hold) if roc_hold is not None else None,\n",
        "            \"classification_report\": cr_hold,\n",
        "            \"confusion_matrix\": cm_hold.tolist()\n",
        "        },\n",
        "        \"models\": [name for name, _ in base_models],\n",
        "        \"meta_model\": \"LogisticRegression\",\n",
        "        \"notes\": \"Base models: RandomForest, ExtraTrees, GradientBoosting. Meta model trained on OOF meta-features (5-fold). Final meta trained on full OOF meta features.\"\n",
        "    }\n",
        "    with open(REPORT_FILE, \"w\") as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "    print(f\"Saved report to: {REPORT_FILE}\")\n",
        "\n",
        "    print(\"\\nDone ✅\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}