{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwixEiFBJIqRNW9ic7GkUQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna-gera/my-aiml-learning/blob/main/day-22/day22_ensemble_blend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG0uMg5y8UF8",
        "outputId": "81df66bf-ec2d-4936-bf91-cba65cc4e3f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial candidates loaded from models/:  []\n",
            "Added quick default candidates:  ['rf_quick', 'gb_quick', 'xgb_quick', 'lgb_quick']\n",
            "\n",
            "-> Processing candidate: rf_quick\n",
            "  rf_quick CV mean: 0.8215 (+/- 0.0271)\n",
            "\n",
            "-> Processing candidate: gb_quick\n",
            "  gb_quick CV mean: 0.8294 (+/- 0.0193)\n",
            "\n",
            "-> Processing candidate: xgb_quick\n",
            "  xgb_quick CV mean: 0.8328 (+/- 0.0223)\n",
            "\n",
            "-> Processing candidate: lgb_quick\n",
            "  lgb_quick CV mean: 0.8305 (+/- 0.0207)\n",
            "\n",
            "Saved candidate CV scores to: outputs/day22_20250929_1619_model_scores.csv\n",
            "Top models selected for blending: ['xgb_quick', 'lgb_quick', 'gb_quick']\n",
            "\n",
            "Searching weight grid for best blend...\n",
            "Saved blend grid results to: outputs/day22_20250929_1619_blend_results.csv\n",
            "Best blend: {'weights': [0.0, 0.0, 1.0], 'accuracy': 0.8439955106621774, 'f1': 0.785824345146379}\n",
            "Fitting pipeline on full data: xgb_quick\n",
            "Fitting pipeline on full data: lgb_quick\n",
            "[LightGBM] [Info] Number of positive: 342, number of negative: 549\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000391 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 440\n",
            "[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 41\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288\n",
            "[LightGBM] [Info] Start training from score -0.473288\n",
            "Fitting pipeline on full data: gb_quick\n",
            "Saved trained pipelines to models/\n",
            "Saved summary to outputs/\n",
            "\n",
            "DONE â€” check outputs/, models/, submissions/\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "day22_ensemble_blend.py\n",
        "Day 22 - Quick ensemble blending & model comparison (2-hour session)\n",
        "\n",
        "What it does:\n",
        "- Loads processed train/test CSVs (fix bool dtypes)\n",
        "- Tries to load tuned models (random search pickles / stacking pipeline) from models/\n",
        "- If not found, trains quick RandomForest & GradientBoosting (+ XGB/LGB if installed)\n",
        "- For each candidate pipeline: computes out-of-fold (OOF) probabilities with StratifiedKFold\n",
        "- Searches a small weight grid for best weighted-average blend (2 or 3 models)\n",
        "- Trains pipelines on full data and writes blended test submission (optional)\n",
        "- Saves outputs to outputs/ and models/\n",
        "\n",
        "Designed to be conservative in runtime to fit a 2-hour window.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from packaging import version\n",
        "import sklearn\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Optional libs\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    HAS_XGB = True\n",
        "except Exception:\n",
        "    HAS_XGB = False\n",
        "\n",
        "try:\n",
        "    from lightgbm import LGBMClassifier\n",
        "    HAS_LGB = True\n",
        "except Exception:\n",
        "    HAS_LGB = False\n",
        "\n",
        "# ----------------- CONFIG -----------------\n",
        "DATA_DIR = Path(\"data/processed\")\n",
        "TRAIN_CSV = DATA_DIR / \"train_processed.csv\"\n",
        "TEST_CSV = DATA_DIR / \"data/processed/test_processed.csv\"  # not required; use your actual path\n",
        "MODELS_DIR = Path(\"models\")\n",
        "OUT_DIR = Path(\"outputs\")\n",
        "SUB_DIR = Path(\"submissions\")\n",
        "\n",
        "for p in [MODELS_DIR, OUT_DIR, SUB_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "CV_FOLDS = 5\n",
        "OOF_N_JOBS = -1\n",
        "SAVE_SUBMISSION = True   # set False if you don't want to save submission\n",
        "MAX_MODELS_TO_BLEND = 3  # try blending top 2-3 models\n",
        "# ------------------------------------------\n",
        "\n",
        "def make_ohe():\n",
        "    \"\"\"Backward-compatible OneHotEncoder factory\"\"\"\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "    if version.parse(sklearn.__version__) >= version.parse(\"1.2\"):\n",
        "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "    return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
        "\n",
        "def load_csv_safe(path):\n",
        "    df = pd.read_csv(path)\n",
        "    # convert bools -> str early to avoid imputer dtype issues\n",
        "    for c in df.select_dtypes(include=[\"bool\"]).columns:\n",
        "        df[c] = df[c].astype(str)\n",
        "    return df\n",
        "\n",
        "def build_preprocessor(X_df):\n",
        "    \"\"\"Build a ColumnTransformer preprocessor from a sample dataframe X_df\"\"\"\n",
        "    Xs = X_df.copy()\n",
        "    # convert bools -> str already done\n",
        "    numeric_features = Xs.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "    categorical_features = Xs.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "    # remove PassengerId if present\n",
        "    for c in (\"PassengerId\",):\n",
        "        if c in numeric_features: numeric_features.remove(c)\n",
        "        if c in categorical_features: categorical_features.remove(c)\n",
        "\n",
        "    num_transformer = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "    cat_transformer = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"MISSING\")),\n",
        "        (\"ohe\", make_ohe())\n",
        "    ])\n",
        "    preprocessor = ColumnTransformer([\n",
        "        (\"num\", num_transformer, numeric_features),\n",
        "        (\"cat\", cat_transformer, categorical_features)\n",
        "    ], remainder=\"drop\")\n",
        "    return preprocessor\n",
        "\n",
        "def find_latest_randomsearch(prefix):\n",
        "    \"\"\"Find latest randomsearch* or model pickles for prefix (e.g. 'random_forest' or 'xgboost')\"\"\"\n",
        "    pattern = str(MODELS_DIR / f\"*{prefix}*randomsearch*.pkl\")\n",
        "    files = sorted(glob.glob(pattern))\n",
        "    return files[-1] if files else None\n",
        "\n",
        "def find_latest_stacking():\n",
        "    files = sorted(glob.glob(str(MODELS_DIR / \"*stacking*pipeline*.pkl\")) + glob.glob(str(MODELS_DIR / \"*stack*pipeline*.pkl\")))\n",
        "    return files[-1] if files else None\n",
        "\n",
        "def load_tuned_estimator(file_path):\n",
        "    \"\"\"Load a RandomizedSearchCV or estimator pickle and return an estimator (best_estimator_ if exists)\"\"\"\n",
        "    try:\n",
        "        obj = joblib.load(file_path)\n",
        "        if hasattr(obj, \"best_estimator_\"):\n",
        "            return obj.best_estimator_\n",
        "        return obj\n",
        "    except Exception as e:\n",
        "        print(\"Failed to load tuned estimator:\", file_path, e)\n",
        "        return None\n",
        "\n",
        "def prepare_candidate_pipelines(preprocessor, X_df):\n",
        "    \"\"\"Return dict{name: pipeline(estimator wrapped with preprocessor)} for candidates.\n",
        "       Prefers tuned models if pickles exist, else trains short default models later.\"\"\"\n",
        "    candidates = {}\n",
        "    # Try load tuned RF\n",
        "    rf_file = find_latest_randomsearch(\"random_forest\")\n",
        "    if rf_file:\n",
        "        est = load_tuned_estimator(rf_file)\n",
        "        if est is not None:\n",
        "            candidates[\"rf_tuned\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", est)])\n",
        "            print(\"Loaded tuned RandomForest from:\", rf_file)\n",
        "\n",
        "    # Try load tuned xgboost\n",
        "    if HAS_XGB:\n",
        "        xgb_file = find_latest_randomsearch(\"xgboost\")\n",
        "        if xgb_file:\n",
        "            est = load_tuned_estimator(xgb_file)\n",
        "            if est is not None:\n",
        "                candidates[\"xgb_tuned\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", est)])\n",
        "                print(\"Loaded tuned XGBoost from:\", xgb_file)\n",
        "\n",
        "    # Try load tuned lightgbm\n",
        "    if HAS_LGB:\n",
        "        lgb_file = find_latest_randomsearch(\"lightgbm\")\n",
        "        if lgb_file:\n",
        "            est = load_tuned_estimator(lgb_file)\n",
        "            if est is not None:\n",
        "                candidates[\"lgb_tuned\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", est)])\n",
        "                print(\"Loaded tuned LightGBM from:\", lgb_file)\n",
        "\n",
        "    # Try stacked pipeline first\n",
        "    stacking_file = find_latest_stacking()\n",
        "    if stacking_file:\n",
        "        try:\n",
        "            stack_pipe = joblib.load(stacking_file)\n",
        "            # If it's a pipeline, keep as candidate\n",
        "            if isinstance(stack_pipe, Pipeline):\n",
        "                candidates[\"stacking_saved\"] = stack_pipe\n",
        "                print(\"Loaded saved stacking pipeline:\", stacking_file)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # If we have few candidates, prepare some default quick models\n",
        "    # (we'll train them quickly on full data when needed)\n",
        "    return candidates\n",
        "\n",
        "def train_quick_models(preprocessor, X, y, names_to_train=(\"rf_quick\",\"gb_quick\",\"xgb_quick\",\"lgb_quick\")):\n",
        "    \"\"\"Train quick base models (faster settings). Returns dict name->pipeline\"\"\"\n",
        "    candidates = {}\n",
        "    if \"rf_quick\" in names_to_train:\n",
        "        rf = RandomForestClassifier(n_estimators=200, max_depth=8, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "        candidates[\"rf_quick\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", rf)])\n",
        "    if \"gb_quick\" in names_to_train:\n",
        "        gb = GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=3, random_state=RANDOM_STATE)\n",
        "        candidates[\"gb_quick\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", gb)])\n",
        "    if HAS_XGB and \"xgb_quick\" in names_to_train:\n",
        "        xgb = XGBClassifier(n_estimators=200, learning_rate=0.05, use_label_encoder=False, eval_metric=\"logloss\", random_state=RANDOM_STATE, n_jobs=1)\n",
        "        candidates[\"xgb_quick\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", xgb)])\n",
        "    if HAS_LGB and \"lgb_quick\" in names_to_train:\n",
        "        lgb = LGBMClassifier(n_estimators=200, learning_rate=0.05, random_state=RANDOM_STATE, n_jobs=1)\n",
        "        candidates[\"lgb_quick\"] = Pipeline([(\"pre\", preprocessor), (\"clf\", lgb)])\n",
        "    return candidates\n",
        "\n",
        "def oof_probs_for_pipeline(pipe, X, y, folds=CV_FOLDS):\n",
        "    \"\"\"Return out-of-fold probabilities (for class 1) using cross_val_predict with method='predict_proba'\"\"\"\n",
        "    cv = StratifiedKFold(n_splits=folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "    # cross_val_predict with predict_proba -> returns shape (n_samples, n_classes)\n",
        "    probs = cross_val_predict(pipe, X, y, cv=cv, method=\"predict_proba\", n_jobs=OOF_N_JOBS)\n",
        "    # return only class 1\n",
        "    return probs[:, 1]\n",
        "\n",
        "def evaluate_oof_blend(oof_probs_list, y_true):\n",
        "    \"\"\"Given list of OOF probability arrays (same length) and y_true, compute accuracy & f1 for equal weights\"\"\"\n",
        "    avg = np.mean(np.vstack(oof_probs_list), axis=0)\n",
        "    preds = (avg >= 0.5).astype(int)\n",
        "    return accuracy_score(y_true, preds), f1_score(y_true, preds)\n",
        "\n",
        "# -------------------- MAIN --------------------\n",
        "def main():\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "    prefix = f\"day22_{ts}\"\n",
        "\n",
        "    # 0) Load data\n",
        "    train = load_csv_safe(TRAIN_CSV)\n",
        "    test_exists = TEST_CSV.exists()\n",
        "    test = load_csv_safe(TEST_CSV) if test_exists else None\n",
        "\n",
        "    if \"Survived\" not in train.columns:\n",
        "        raise SystemExit(\"train_processed.csv must contain 'Survived' column\")\n",
        "\n",
        "    X_full = train.drop(columns=[\"Survived\"])\n",
        "    y_full = train[\"Survived\"].astype(int)\n",
        "\n",
        "    # 1) Build preprocessor using X_full as sample\n",
        "    preprocessor = build_preprocessor(X_full)\n",
        "\n",
        "    # 2) Prepare candidate pipelines (load tuned if possible)\n",
        "    candidates = prepare_candidate_pipelines(preprocessor, X_full)\n",
        "    print(\"Initial candidates loaded from models/: \", list(candidates.keys()))\n",
        "\n",
        "    # 3) If too few candidates, add quick defaults and train them now\n",
        "    if len(candidates) < 2:\n",
        "        quick = train_quick_models(preprocessor, X_full, y_full)\n",
        "        candidates.update(quick)\n",
        "        print(\"Added quick default candidates: \", [k for k in quick.keys()])\n",
        "\n",
        "    # 4) For each candidate, compute OOF probs (cross-validated)\n",
        "    oof_dict = {}\n",
        "    model_scores = []\n",
        "    for name, pipe in candidates.items():\n",
        "        print(f\"\\n-> Processing candidate: {name}\")\n",
        "        # Fit on full data if pipeline contains an estimator with fit requirement? cross_val_predict will fit internally\n",
        "        try:\n",
        "            # compute OOF probabilities\n",
        "            probs = oof_probs_for_pipeline(pipe, X_full, y_full, folds=CV_FOLDS)\n",
        "            oof_dict[name] = probs\n",
        "            # compute CV accuracy using pipeline (simple)\n",
        "            cv_scores = cross_val_score(pipe, X_full, y_full, cv=CV_FOLDS, scoring=\"accuracy\", n_jobs=-1)\n",
        "            mean_cv = float(np.mean(cv_scores))\n",
        "            model_scores.append({\"name\": name, \"cv_mean\": mean_cv, \"cv_std\": float(np.std(cv_scores))})\n",
        "            print(f\"  {name} CV mean: {mean_cv:.4f} (+/- {np.std(cv_scores):.4f})\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Failed to compute OOF for {name}: {e}\")\n",
        "\n",
        "    # Save model_scores\n",
        "    df_scores = pd.DataFrame(model_scores).sort_values(\"cv_mean\", ascending=False)\n",
        "    out_scores = OUT_DIR / f\"{prefix}_model_scores.csv\"\n",
        "    df_scores.to_csv(out_scores, index=False)\n",
        "    print(\"\\nSaved candidate CV scores to:\", out_scores)\n",
        "\n",
        "    # 5) Choose top models to blend (by cv_mean)\n",
        "    top_names = df_scores[\"name\"].tolist()[:MAX_MODELS_TO_BLEND]\n",
        "    print(\"Top models selected for blending:\", top_names)\n",
        "    oof_list = [oof_dict[n] for n in top_names]\n",
        "\n",
        "    # 6) Weighted blend search (supports 2 or 3 models)\n",
        "    print(\"\\nSearching weight grid for best blend...\")\n",
        "    best = {\"weights\": None, \"accuracy\": -1, \"f1\": -1}\n",
        "    results = []\n",
        "    if len(oof_list) == 1:\n",
        "        # nothing to blend, evaluate single model\n",
        "        acc, f1 = accuracy_score(y_full, (oof_list[0] >= 0.5).astype(int)), f1_score(y_full, (oof_list[0] >= 0.5).astype(int))\n",
        "        best = {\"weights\": [1.0], \"accuracy\": acc, \"f1\": f1}\n",
        "        results.append({\"w\": \"1.0\", \"accuracy\": acc, \"f1\": f1})\n",
        "    elif len(oof_list) == 2:\n",
        "        w_range = np.linspace(0, 1, 21)\n",
        "        for w in w_range:\n",
        "            blended = w * oof_list[0] + (1 - w) * oof_list[1]\n",
        "            preds = (blended >= 0.5).astype(int)\n",
        "            acc = accuracy_score(y_full, preds)\n",
        "            f1 = f1_score(y_full, preds)\n",
        "            results.append({\"w1\": float(w), \"w2\": float(1 - w), \"accuracy\": float(acc), \"f1\": float(f1)})\n",
        "            if acc > best[\"accuracy\"]:\n",
        "                best = {\"weights\": [float(w), float(1 - w)], \"accuracy\": float(acc), \"f1\": float(f1)}\n",
        "    else:\n",
        "        # 3 models: loop w1,w2, w3 = 1-w1-w2 with coarse grid\n",
        "        steps = np.linspace(0, 1, 11)\n",
        "        for w1 in steps:\n",
        "            for w2 in steps:\n",
        "                if w1 + w2 > 1.0:\n",
        "                    continue\n",
        "                w3 = 1.0 - w1 - w2\n",
        "                blended = w1 * oof_list[0] + w2 * oof_list[1] + w3 * oof_list[2]\n",
        "                preds = (blended >= 0.5).astype(int)\n",
        "                acc = accuracy_score(y_full, preds)\n",
        "                f1 = f1_score(y_full, preds)\n",
        "                results.append({\"w1\": float(w1), \"w2\": float(w2), \"w3\": float(w3), \"accuracy\": float(acc), \"f1\": float(f1)})\n",
        "                if acc > best[\"accuracy\"]:\n",
        "                    best = {\"weights\": [float(w1), float(w2), float(w3)], \"accuracy\": float(acc), \"f1\": float(f1)}\n",
        "\n",
        "    # save results\n",
        "    df_results = pd.DataFrame(results)\n",
        "    out_grid = OUT_DIR / f\"{prefix}_blend_results.csv\"\n",
        "    df_results.to_csv(out_grid, index=False)\n",
        "    print(\"Saved blend grid results to:\", out_grid)\n",
        "    print(\"Best blend:\", best)\n",
        "\n",
        "    # 7) Train top pipelines on full data and produce blended test submission if requested\n",
        "    trained_pipelines = {}\n",
        "    for name in top_names:\n",
        "        pipe = candidates[name]\n",
        "        print(\"Fitting pipeline on full data:\", name)\n",
        "        pipe.fit(X_full, y_full)\n",
        "        trained_pipelines[name] = pipe\n",
        "        # optionally save each pipeline\n",
        "    joblib.dump(trained_pipelines, MODELS_DIR / f\"{prefix}_pipelines.pkl\")\n",
        "    print(\"Saved trained pipelines to models/\")\n",
        "\n",
        "    if SAVE_SUBMISSION and test is not None:\n",
        "        print(\"Generating blended submission on test set...\")\n",
        "        # compute test probs for each top model\n",
        "        test_probs = []\n",
        "        for name in top_names:\n",
        "            p = trained_pipelines[name].predict_proba(test)[:, 1]\n",
        "            test_probs.append(p)\n",
        "        # apply best weights\n",
        "        if len(best[\"weights\"]) == 1:\n",
        "            blended_test_probs = test_probs[0]\n",
        "        elif len(best[\"weights\"]) == 2:\n",
        "            blended_test_probs = best[\"weights\"][0] * test_probs[0] + best[\"weights\"][1] * test_probs[1]\n",
        "        else:\n",
        "            blended_test_probs = np.zeros_like(test_probs[0])\n",
        "            for w, p in zip(best[\"weights\"], test_probs):\n",
        "                blended_test_probs += w * p\n",
        "        # produce class preds using 0.5 threshold (or consider using best[\"accuracy\"] threshold tune)\n",
        "        test_pred_labels = (blended_test_probs >= 0.5).astype(int)\n",
        "        # handle PassengerId if present in test\n",
        "        if \"PassengerId\" in test.columns:\n",
        "            pid = test[\"PassengerId\"]\n",
        "        else:\n",
        "            pid = np.arange(1, len(test) + 1)\n",
        "        submission = pd.DataFrame({\"PassengerId\": pid, \"Survived\": test_pred_labels})\n",
        "        out_sub = SUB_DIR / f\"{prefix}_blend_submission.csv\"\n",
        "        submission.to_csv(out_sub, index=False)\n",
        "        print(\"Saved blended submission to:\", out_sub)\n",
        "\n",
        "    # 8) Save summary\n",
        "    summary = {\n",
        "        \"timestamp\": ts,\n",
        "        \"top_models\": top_names,\n",
        "        \"best_weights\": best[\"weights\"],\n",
        "        \"best_accuracy\": best[\"accuracy\"],\n",
        "        \"best_f1\": best[\"f1\"]\n",
        "    }\n",
        "    pd.Series(summary).to_frame(\"value\").to_csv(OUT_DIR / f\"{prefix}_summary.csv\")\n",
        "    print(\"Saved summary to outputs/\")\n",
        "\n",
        "    print(\"\\nDONE â€” check outputs/, models/, submissions/\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}