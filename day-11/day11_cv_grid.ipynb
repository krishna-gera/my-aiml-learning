{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbLM0BF+p2e8OTXhCxD7Nz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna-gera/my-aiml-learning/blob/main/day-11/day11_cv_grid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnvkDymY_T55"
      },
      "outputs": [],
      "source": [
        "# day11_cv_grid.py\n",
        "# Usage: python day11_cv_grid.py\n",
        "# Outputs:\n",
        "#  - day11/day11_gridsearch_results.csv\n",
        "#  - day11/day11_results.json\n",
        "#  - day11/assets/best_model.joblib\n",
        "#  - day11/assets/plots/*\n",
        "\n",
        "import warnings, json\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from sklearn.model_selection import (train_test_split, StratifiedKFold,\n",
        "                                     cross_val_score, GridSearchCV, RandomizedSearchCV)\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, confusion_matrix, roc_curve, classification_report)\n",
        "import joblib\n",
        "\n",
        "OUT = Path(\"day11\"); OUT.mkdir(exist_ok=True)\n",
        "ASSETS = OUT/\"assets\"; ASSETS.mkdir(exist_ok=True)\n",
        "\n",
        "# ---- 0) Load processed data (use best available)\n",
        "candidates = [\n",
        "    Path(\"day10/day10_titanic_feat.csv\"),\n",
        "    Path(\"day05/day05_titanic_feat.csv\"),\n",
        "    Path(\"day02/day02_titanic_clean.csv\"),\n",
        "    Path(\"train.csv\")\n",
        "]\n",
        "df = None\n",
        "for p in candidates:\n",
        "    if p.exists():\n",
        "        print(\"Loading:\", p)\n",
        "        df = pd.read_csv(p)\n",
        "        break\n",
        "if df is None:\n",
        "    raise FileNotFoundError(\"No input CSV found. Place processed file in one of the candidate paths.\")\n",
        "\n",
        "# ---- 1) Prepare X, y (safe)\n",
        "if 'Survived' not in df.columns:\n",
        "    raise KeyError(\"Dataset must contain 'Survived' column.\")\n",
        "\n",
        "# drop obvious meta columns (if present)\n",
        "for c in ['PassengerId','Ticket','Cabin','Name']:\n",
        "    if c in df.columns: df.drop(columns=[c], inplace=True)\n",
        "\n",
        "# If categorical strings remain, one-hot them quickly (safe)\n",
        "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
        "cat_cols = [c for c in cat_cols if c != 'Survived']\n",
        "if cat_cols:\n",
        "    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
        "\n",
        "X = df.drop(columns=['Survived'])\n",
        "y = df['Survived']\n",
        "\n",
        "# split a holdout test set (optional but recommended)\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n",
        "\n",
        "# ---- 2) Quick CV baseline scores\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=2000),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "}\n",
        "print(\"\\nBaseline cross_val_score (f1):\")\n",
        "for name, mdl in models.items():\n",
        "    scores = cross_val_score(mdl, X_train_full, y_train_full, cv=cv, scoring='f1', n_jobs=-1)\n",
        "    print(f\" {name}: mean f1 = {scores.mean():.4f}, std = {scores.std():.4f}\")\n",
        "\n",
        "# ---- 3) Build a simple pipeline (preprocessing here is trivial since features are numeric after Day10)\n",
        "# If you have a preprocessor saved from Day10, you can load it and use it here.\n",
        "pipeline_rf = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),  # numeric scaling often helps some models\n",
        "    (\"clf\", RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# ---- 4) GridSearchCV (small grid) for RandomForest\n",
        "param_grid = {\n",
        "    \"clf__n_estimators\": [100, 200],\n",
        "    \"clf__max_depth\": [4, 6, None],\n",
        "    \"clf__max_features\": [\"sqrt\", \"log2\"]\n",
        "}\n",
        "gs = GridSearchCV(pipeline_rf, param_grid, cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=42),\n",
        "                  scoring='f1', n_jobs=-1, verbose=1, return_train_score=True)\n",
        "print(\"\\nRunning GridSearchCV (this may take a few minutes)...\")\n",
        "gs.fit(X_train_full, y_train_full)\n",
        "\n",
        "# Save full cv results to CSV (Day5 style)\n",
        "pd.DataFrame(gs.cv_results_).to_csv(OUT / \"day11_gridsearch_results.csv\", index=False)\n",
        "print(\"GridSearchCV results saved to:\", OUT / \"day11_gridsearch_results.csv\")\n",
        "\n",
        "# Best params & CV score\n",
        "best_params = gs.best_params_\n",
        "best_score = gs.best_score_\n",
        "print(\"Best params:\", best_params)\n",
        "print(\"Best CV f1:\", best_score)\n",
        "\n",
        "# Evaluate best model on holdout test\n",
        "best_model = gs.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_proba = best_model.predict_proba(X_test)[:,1] if hasattr(best_model, \"predict_proba\") else None\n",
        "\n",
        "metrics = {\n",
        "    \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
        "    \"precision\": float(precision_score(y_test, y_pred)),\n",
        "    \"recall\": float(recall_score(y_test, y_pred)),\n",
        "    \"f1\": float(f1_score(y_test, y_pred)),\n",
        "    \"roc_auc\": float(roc_auc_score(y_test, y_proba)) if y_proba is not None else None\n",
        "}\n",
        "print(\"\\nTest metrics:\", json.dumps(metrics, indent=2))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Save model & results summary\n",
        "joblib.dump(best_model, ASSETS / \"best_model.joblib\")\n",
        "with open(OUT / \"day11_results.json\", \"w\") as f:\n",
        "    json.dump({\"best_params\": best_params, \"cv_best_score\": best_score, \"test_metrics\": metrics}, f, indent=2)\n",
        "\n",
        "# ---- 5) Optional: RandomizedSearchCV (wider but faster)\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "param_dist = {\n",
        "    \"clf__n_estimators\": [50,100,200,300],\n",
        "    \"clf__max_depth\": [3,4,6,8, None],\n",
        "    \"clf__max_features\": [\"sqrt\",\"log2\", None],\n",
        "    \"clf__min_samples_split\": [2,5,10]\n",
        "}\n",
        "rs = RandomizedSearchCV(pipeline_rf, param_distributions=param_dist, n_iter=12, cv=3, scoring='f1', n_jobs=-1, random_state=42, verbose=1)\n",
        "print(\"\\nRunning RandomizedSearchCV (optional)...\")\n",
        "rs.fit(X_train_full, y_train_full)\n",
        "pd.DataFrame(rs.cv_results_).to_csv(OUT / \"day11_randomsearch_results.csv\", index=False)\n",
        "print(\"RandomSearch results saved to:\", OUT / \"day11_randomsearch_results.csv\")\n",
        "joblib.dump(rs.best_estimator_, ASSETS / \"best_model_randomsearch.joblib\")\n",
        "\n",
        "# ---- 6) Quick plots: best confusion matrix & ROC (if proba)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4,3)); sns.heatmap(cm, annot=True, fmt='d'); plt.title(\"Best Model Confusion\"); plt.savefig(ASSETS / \"best_confusion.png\"); plt.close()\n",
        "\n",
        "if y_proba is not None:\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "    plt.figure(figsize=(5,4)); plt.plot(fpr,tpr,label=f\"AUC={metrics['roc_auc']:.3f}\"); plt.plot([0,1],[0,1],'--',color='gray'); plt.legend(); plt.title(\"ROC\"); plt.savefig(ASSETS / \"best_roc.png\"); plt.close()\n",
        "\n",
        "print(\"Saved models and plots to\", ASSETS)\n",
        "print(\"Day 11 complete âœ…\")\n"
      ]
    }
  ]
}