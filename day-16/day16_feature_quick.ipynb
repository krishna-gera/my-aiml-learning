{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYWWcPdLXJNYeNlLt7pZV7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna-gera/my-aiml-learning/blob/main/day-16/day16_feature_quick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H926WiW33M3X",
        "outputId": "a1e7c6d0-4655-4935-8a20-9cfe741c9878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Day16 run started: 2025-09-23T14:01:17.124712\n",
            "\n",
            "1) Baseline evaluation on existing processed features...\n",
            "Baseline CV acc (mean): 0.8294  std: 0.0196\n",
            "Baseline fold scores: [0.8603 0.8315 0.8146 0.8034 0.8371]\n",
            "\n",
            "2) Adding features (if missing) to train/test...\n",
            "\n",
            "After FE CV acc (mean): 0.8305  std: 0.0151\n",
            "After FE fold scores: [0.8603 0.8258 0.8258 0.8202 0.8202]\n",
            "\n",
            "Delta (FE - baseline): 0.0011\n",
            "\n",
            "3) Training RF on full FE data to show top features (quick check)...\n",
            "Top 10 features by importance:\n",
            " PassengerId        0.119967\n",
            "Title_Mr           0.113627\n",
            "Sex_male           0.107291\n",
            "Age                0.092962\n",
            "FarePerPerson      0.084676\n",
            "Fare               0.082743\n",
            "Fare_log           0.081013\n",
            "Pclass             0.038915\n",
            "TicketGroupSize    0.037655\n",
            "FamilySize         0.030356\n",
            "dtype: float64\n",
            "\n",
            "Done. Elapsed: 0:00:09.318970\n",
            "Saved FE files + summary in: /content/outputs\n"
          ]
        }
      ],
      "source": [
        "# day16_feature_quick.py\n",
        "# Day 16: quick, safe feature engineering + CV comparison (2-hour plan)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "import datetime\n",
        "\n",
        "# ------- CONFIG -------\n",
        "DATA_DIR = Path(\"data/processed\")\n",
        "OUT_DIR = Path(\"outputs\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "TRAIN_CSV = DATA_DIR / \"train_processed.csv\"\n",
        "TEST_CSV = DATA_DIR / \"test_processed.csv\"\n",
        "RANDOM_STATE = 42\n",
        "CV_FOLDS = 5\n",
        "# ----------------------\n",
        "\n",
        "def add_features_if_missing(df):\n",
        "    \"\"\"Add commonly useful Titanic features only if they are NOT already present.\"\"\"\n",
        "    df = df.copy()\n",
        "    # FamilySize\n",
        "    if \"FamilySize\" not in df.columns and {\"SibSp\", \"Parch\"}.issubset(df.columns):\n",
        "        df[\"FamilySize\"] = df[\"SibSp\"].fillna(0).astype(int) + df[\"Parch\"].fillna(0).astype(int) + 1\n",
        "    # IsAlone\n",
        "    if \"IsAlone\" not in df.columns and \"FamilySize\" in df.columns:\n",
        "        df[\"IsAlone\"] = (df[\"FamilySize\"] == 1).astype(int)\n",
        "    # Title from Name\n",
        "    if \"Title\" not in df.columns and \"Name\" in df.columns:\n",
        "        df[\"Title\"] = df[\"Name\"].str.extract(r\",\\s*([^\\.]+)\\.\", expand=False).str.strip()\n",
        "        df[\"Title\"] = df[\"Title\"].replace({\n",
        "            \"Mlle\":\"Miss\",\"Ms\":\"Miss\",\"Mme\":\"Mrs\",\n",
        "            \"Lady\":\"Royal\",\"Countess\":\"Royal\",\"Sir\":\"Royal\",\"Don\":\"Royal\",\"Dona\":\"Royal\",\n",
        "            \"Jonkheer\":\"Royal\",\"Col\":\"Officer\",\"Capt\":\"Officer\",\"Major\":\"Officer\"\n",
        "        }).fillna(\"Other\")\n",
        "    # FarePerPerson\n",
        "    if \"FarePerPerson\" not in df.columns and \"Fare\" in df.columns:\n",
        "        if \"FamilySize\" in df.columns:\n",
        "            df[\"FarePerPerson\"] = df[\"Fare\"].fillna(0) / df[\"FamilySize\"].replace(0, 1)\n",
        "        else:\n",
        "            df[\"FarePerPerson\"] = df[\"Fare\"].fillna(0)\n",
        "    # AgeBin\n",
        "    if \"AgeBin\" not in df.columns and \"Age\" in df.columns:\n",
        "        df[\"AgeBin\"] = pd.cut(df[\"Age\"].fillna(df[\"Age\"].median()),\n",
        "                              bins=[0,12,20,35,60,200], labels=False, include_lowest=True)\n",
        "    # Ticket prefix\n",
        "    if \"TicketPrefix\" not in df.columns and \"Ticket\" in df.columns:\n",
        "        df[\"TicketPrefix\"] = df[\"Ticket\"].astype(str).str.replace(r'[\\d\\./]', '', regex=True).str.strip().str.split().str[0].replace(\"\", \"NO\")\n",
        "    return df\n",
        "\n",
        "def encode_and_impute(X_train_df, X_test_df=None):\n",
        "    \"\"\"One-hot encode object columns, align train/test, then median-impute numeric NaNs.\"\"\"\n",
        "    # One-hot encode all object columns\n",
        "    X_train_enc = pd.get_dummies(X_train_df, dummy_na=False)\n",
        "    if X_test_df is not None:\n",
        "        X_test_enc = pd.get_dummies(X_test_df, dummy_na=False)\n",
        "        # Align columns (train cols -> test, fill missing with 0)\n",
        "        X_train_enc, X_test_enc = X_train_enc.align(X_test_enc, join=\"left\", axis=1, fill_value=0)\n",
        "    else:\n",
        "        X_test_enc = None\n",
        "\n",
        "    imputer = SimpleImputer(strategy=\"median\")\n",
        "    X_train_imp = pd.DataFrame(imputer.fit_transform(X_train_enc), columns=X_train_enc.columns)\n",
        "    if X_test_enc is not None:\n",
        "        X_test_imp = pd.DataFrame(imputer.transform(X_test_enc), columns=X_test_enc.columns)\n",
        "    else:\n",
        "        X_test_imp = None\n",
        "\n",
        "    return X_train_imp, X_test_imp\n",
        "\n",
        "def cv_score(clf, X, y, folds=CV_FOLDS):\n",
        "    cv = StratifiedKFold(n_splits=folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "    scores = cross_val_score(clf, X, y, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "    return scores\n",
        "\n",
        "def main():\n",
        "    t0 = datetime.datetime.now()\n",
        "    print(f\"Day16 run started: {t0.isoformat()}\\n\")\n",
        "\n",
        "    # Load\n",
        "    train = pd.read_csv(TRAIN_CSV)\n",
        "    test = pd.read_csv(TEST_CSV)\n",
        "\n",
        "    # Ensure target exists\n",
        "    if \"Survived\" not in train.columns:\n",
        "        raise ValueError(\"train_processed.csv must contain 'Survived' column.\")\n",
        "\n",
        "    # --- Baseline (existing processed features) ---\n",
        "    print(\"1) Baseline evaluation on existing processed features...\")\n",
        "    X_base = train.drop([\"Survived\"], axis=1, errors=\"ignore\")\n",
        "    y = train[\"Survived\"]\n",
        "    # If test has Survived col (NaN), drop it\n",
        "    test_for_align = test.drop([\"Survived\"], axis=1, errors=\"ignore\")\n",
        "\n",
        "    X_base_enc, _ = encode_and_impute(X_base, test_for_align)\n",
        "    clf = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "    base_scores = cv_score(clf, X_base_enc, y)\n",
        "    print(f\"Baseline CV acc (mean): {base_scores.mean():.4f}  std: {base_scores.std():.4f}\")\n",
        "    print(\"Baseline fold scores:\", np.round(base_scores, 4))\n",
        "\n",
        "    # --- Add features (only if missing) ---\n",
        "    print(\"\\n2) Adding features (if missing) to train/test...\")\n",
        "    train_fe = add_features_if_missing(train)\n",
        "    test_fe = add_features_if_missing(test)\n",
        "\n",
        "    # Drop 'Survived' from test (if present)\n",
        "    test_fe = test_fe.drop([\"Survived\"], axis=1, errors=\"ignore\")\n",
        "\n",
        "    # --- Encode + Impute after FE ---\n",
        "    X_fe = train_fe.drop([\"Survived\"], axis=1, errors=\"ignore\")\n",
        "    X_fe_enc, X_test_enc = encode_and_impute(X_fe, test_fe)\n",
        "\n",
        "    # Re-run CV with same classifier (keeps it comparable)\n",
        "    fe_scores = cv_score(clf, X_fe_enc, y)\n",
        "    print(f\"\\nAfter FE CV acc (mean): {fe_scores.mean():.4f}  std: {fe_scores.std():.4f}\")\n",
        "    print(\"After FE fold scores:\", np.round(fe_scores, 4))\n",
        "    print(f\"\\nDelta (FE - baseline): {fe_scores.mean() - base_scores.mean():.4f}\")\n",
        "\n",
        "    # Train on full FE data to inspect feature importances quickly\n",
        "    print(\"\\n3) Training RF on full FE data to show top features (quick check)...\")\n",
        "    clf_full = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "    clf_full.fit(X_fe_enc, y)\n",
        "    importances = pd.Series(clf_full.feature_importances_, index=X_fe_enc.columns).sort_values(ascending=False)\n",
        "    print(\"Top 10 features by importance:\\n\", importances.head(10))\n",
        "\n",
        "    # Save FE'd CSVs (optional) and a short result log\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "    train_fe.to_csv(OUT_DIR / f\"train_processed_fe_{timestamp}.csv\", index=False)\n",
        "    test_fe.to_csv(OUT_DIR / f\"test_processed_fe_{timestamp}.csv\", index=False)\n",
        "\n",
        "    summary = {\n",
        "        \"time\": timestamp,\n",
        "        \"baseline_cv_mean\": float(base_scores.mean()),\n",
        "        \"fe_cv_mean\": float(fe_scores.mean()),\n",
        "        \"delta\": float((fe_scores.mean() - base_scores.mean()))\n",
        "    }\n",
        "    pd.Series(summary).to_frame(\"value\").to_csv(OUT_DIR / f\"day16_summary_{timestamp}.csv\")\n",
        "\n",
        "    t1 = datetime.datetime.now()\n",
        "    print(f\"\\nDone. Elapsed: {t1 - t0}\")\n",
        "    print(f\"Saved FE files + summary in: {OUT_DIR.resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}