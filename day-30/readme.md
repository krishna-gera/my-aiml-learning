
# ğŸš€ 30 Days AI/ML Challenge â€” Final Project (Day 30)

Welcome to the **final project** of my **30 Days AI/ML Challenge**! ğŸ‰
Over the past month, I have built projects every single day to explore, practice, and apply **Machine Learning concepts**.

Today (Day 30), I wrapped up the challenge with a **Gradio-powered Web App** that allows you to upload a CSV file and get predictions on Titanic survival ğŸš¢.

---

## ğŸ“Œ Day 30 Project: Titanic Survival Predictor (Gradio App)

### ğŸ”¹ What it does

* Upload a CSV file with Titanic passenger data
* The app preprocesses the data using the trained pipeline
* It predicts **Survived (1) or Not Survived (0)** using my final stacked model
* Download the results instantly

### ğŸ”¹ How to Run (Colab/Local)

1. Clone this repository or open in Google Colab.
2. Place the trained model file: `day28_models.joblib` in your working directory.
3. Run the script:

   ```bash
   python day30_gradio_app.py
   ```
4. Open the Gradio link â†’ upload a `.csv` file â†’ get predictions.

---

## ğŸ“– 30-Day Journey Recap

Hereâ€™s what I accomplished each day:

### ğŸ”¹ Week 1: Foundations (Day 1â€“7)

* Learned Python, Pandas, Numpy basics
* Data preprocessing (handling missing values, encoding, scaling)
* First ML models: Logistic Regression, Decision Trees
* Evaluated models using accuracy, confusion matrix

### ğŸ”¹ Week 2: Deeper into ML (Day 8â€“14)

* Random Forests, Gradient Boosting
* Hyperparameter tuning with GridSearchCV
* Cross-validation
* Feature importance analysis
* Worked on Kaggleâ€™s Titanic dataset end-to-end

### ğŸ”¹ Week 3: Advancing (Day 15â€“21)

* Tried advanced models: XGBoost, LightGBM, CatBoost
* Created ensembles (Voting Classifier, Bagging)
* Built clean pipelines with Scikit-Learn
* Learned model persistence with `joblib`
* Explored Kaggle submissions + score improvements

### ğŸ”¹ Week 4: Real Projects (Day 22â€“28)

* Built reusable preprocessing scripts
* Stacked models for better predictions
* Auto feature engineering + normalization
* Tested different thresholds for probability-based classification
* Finalized best ensemble (stacking model + rules)

### ğŸ”¹ Day 29: Deployment-Ready

* Cleaned and finalized the trained models
* Created a CSV prediction script with error handling
* Exported ready-to-use prediction outputs

### ğŸ”¹ Day 30: Final Web App ğŸ¯

* Built a **Gradio Web App** for Titanic predictions
* Added CSV upload + download feature
* Public link â†’ anyone can test predictions in real-time

---

## ğŸ¯ Key Learnings

* End-to-end ML workflow (data â†’ model â†’ evaluation â†’ deployment)
* Model selection, stacking, and threshold tuning
* Using Kaggle datasets to practice real-world workflows
* Packaging & deploying models via **Gradio apps**

---

## ğŸ† Final Thoughts

This 30-day journey was challenging but highly rewarding.
Every day brought new errors, debugging sessions, and learnings.

ğŸ’¡ Now, I feel confident about:

* Quickly prototyping ML models
* Writing clean and reproducible ML code
* Sharing ML projects publicly (GitHub + LinkedIn)
* Taking on bigger AI/ML projects ğŸš€

---

âœ¨ **Thank you for following along my 30-day journey!**
This is just the beginning â€” more advanced AI/ML projects coming soon ğŸ˜‰
