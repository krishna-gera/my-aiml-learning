{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRusFhtKp2rTK477QFXQTa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna-gera/my-aiml-learning/blob/main/day-2/day2_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XoK5RC0M8Ty4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc98cc9-1686-4edb-cffb-3e633b45219c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Day 2 cleaning script starting ===\n",
            "Found train file at: /content/train.csv\n",
            "Raw data shape: (891, 12)\n",
            "Saved cleaned (minimal) dataset -> day02/day02_titanic_clean.csv (shape: (891, 12))\n",
            "Saved preserved dataset -> day02/day02_titanic_preserved.csv (shape: (891, 15))\n",
            "\n",
            "--- Quick checks on cleaned file ---\n",
            "Columns: ['PassengerId', 'Survived', 'Pclass', 'Sex', 'Sex_bin', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'IsAlone']\n",
            "Missing values per column:\n",
            " PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Sex            0\n",
            "Sex_bin        0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "FamilySize     0\n",
            "IsAlone        0\n",
            "dtype: int64\n",
            "\n",
            "Sample rows:\n",
            "  PassengerId  Survived  Pclass    Sex  Sex_bin  Age  SibSp  Parch    Fare Embarked  FamilySize  IsAlone\n",
            "           1         0       3   male        1 22.0      1      0  7.2500        S           2        0\n",
            "           2         1       1 female        0 38.0      1      0 71.2833        C           2        0\n",
            "           3         1       3 female        0 26.0      0      0  7.9250        S           1        1\n",
            "           4         1       1 female        0 35.0      1      0 53.1000        S           2        0\n",
            "           5         0       3   male        1 35.0      0      0  8.0500        S           1        1\n",
            "\n",
            "If everything looks good, commit the files:\n",
            "  git add day02/*\n",
            "  git commit -m \"Day 2: Titanic cleaned dataset saved\"\n",
            "  git push\n",
            "=== Done ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-218996352.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
            "/tmp/ipython-input-218996352.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
            "/tmp/ipython-input-218996352.py:57: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Embarked'].fillna(mode_emb, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# create_day02_clean.py\n",
        "# Run this from your project root (where you normally run your notebooks / scripts).\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import sys\n",
        "\n",
        "def find_train_csv():\n",
        "    search_paths = [\n",
        "        Path(\"train.csv\"),\n",
        "        Path(\"data/train.csv\"),\n",
        "        Path(\"datasets/train.csv\"),\n",
        "        Path(\"input/train.csv\"),\n",
        "        Path(\"../train.csv\"),\n",
        "        Path(\"day02/train.csv\")\n",
        "    ]\n",
        "    for p in search_paths:\n",
        "        if p.exists():\n",
        "            return p.resolve()\n",
        "    # try a quick glob search under current folder\n",
        "    for p in Path('.').rglob('train*.csv'):\n",
        "        return p.resolve()\n",
        "    return None\n",
        "\n",
        "def safe_read_csv(path):\n",
        "    try:\n",
        "        return pd.read_csv(path)\n",
        "    except UnicodeDecodeError:\n",
        "        # fallback common encodings\n",
        "        return pd.read_csv(path, encoding='latin1')\n",
        "    except Exception as e:\n",
        "        raise\n",
        "\n",
        "def prepare_clean_files(df):\n",
        "    # Ensure expected columns exist\n",
        "    expected = {'PassengerId','Survived','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked'}\n",
        "    present = set(df.columns)\n",
        "    missing = expected - present\n",
        "    if missing:\n",
        "        print(f\"[Warning] Missing columns in train.csv: {missing}. Proceeding with columns that exist.\")\n",
        "    # 1) Basic repairs for numeric columns\n",
        "    if 'Fare' in df.columns:\n",
        "        df['Fare'] = pd.to_numeric(df['Fare'], errors='coerce')\n",
        "        df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
        "    if 'Age' in df.columns:\n",
        "        df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
        "        df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "    # 2) Embarked fill\n",
        "    if 'Embarked' in df.columns:\n",
        "        if df['Embarked'].isna().any():\n",
        "            try:\n",
        "                mode_emb = df['Embarked'].mode()[0]\n",
        "            except Exception:\n",
        "                mode_emb = 'S'\n",
        "            df['Embarked'].fillna(mode_emb, inplace=True)\n",
        "    # 3) Family features\n",
        "    if 'SibSp' in df.columns and 'Parch' in df.columns:\n",
        "        df['FamilySize'] = df['SibSp'].fillna(0).astype(int) + df['Parch'].fillna(0).astype(int) + 1\n",
        "        df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
        "    # 4) Sex to binary (keep original too)\n",
        "    if 'Sex' in df.columns:\n",
        "        df['Sex_bin'] = df['Sex'].map(lambda x: 1 if str(x).lower().startswith('m') else 0)\n",
        "    # 5) Keep a minimal cleaned table for Day 2 usage\n",
        "    minimal_cols = []\n",
        "    for c in ['PassengerId','Survived','Pclass','Sex','Sex_bin','Age','SibSp','Parch','Fare','Embarked','FamilySize','IsAlone']:\n",
        "        if c in df.columns:\n",
        "            minimal_cols.append(c)\n",
        "    df_min = df[minimal_cols].copy()\n",
        "    # 6) Save both minimal cleaned file and a preserved copy with Name/Cabin/Ticket for later feature engineering\n",
        "    return df_min, df\n",
        "\n",
        "def main():\n",
        "    print(\"=== Day 2 cleaning script starting ===\")\n",
        "    train_path = find_train_csv()\n",
        "    if train_path is None:\n",
        "        print(\"ERROR: Could not find train.csv. Please download Titanic train.csv from Kaggle and place it in project root or data/ folder.\")\n",
        "        print(\"Common locations checked: ./train.csv, ./data/train.csv, ./datasets/train.csv, ./input/train.csv\")\n",
        "        sys.exit(1)\n",
        "    print(f\"Found train file at: {train_path}\")\n",
        "    df_raw = safe_read_csv(train_path)\n",
        "    print(\"Raw data shape:\", df_raw.shape)\n",
        "    # Prepare cleaned minimal + preserved raw copy\n",
        "    df_min, df_preserved = prepare_clean_files(df_raw)\n",
        "    # Ensure output folder exists\n",
        "    out_dir = Path(\"day02\")\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    clean_path = out_dir / \"day02_titanic_clean.csv\"\n",
        "    preserved_path = out_dir / \"day02_titanic_preserved.csv\"\n",
        "    # Save CSVs\n",
        "    df_min.to_csv(clean_path, index=False)\n",
        "    df_preserved.to_csv(preserved_path, index=False)\n",
        "    print(f\"Saved cleaned (minimal) dataset -> {clean_path} (shape: {df_min.shape})\")\n",
        "    print(f\"Saved preserved dataset -> {preserved_path} (shape: {df_preserved.shape})\")\n",
        "    # Quick sanity checks\n",
        "    print(\"\\n--- Quick checks on cleaned file ---\")\n",
        "    print(\"Columns:\", list(df_min.columns))\n",
        "    print(\"Missing values per column:\\n\", df_min.isna().sum())\n",
        "    print(\"\\nSample rows:\\n\", df_min.head().to_string(index=False))\n",
        "    print(\"\\nIf everything looks good, commit the files:\\n  git add day02/*\\n  git commit -m \\\"Day 2: Titanic cleaned dataset saved\\\"\\n  git push\")\n",
        "    print(\"=== Done ===\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}
