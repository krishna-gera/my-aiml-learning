{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/mO6Ug++ScYK4Sb8kdR1n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna-gera/my-aiml-learning/blob/main/day-8/day08_trees_rf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiLBD7_zLTwH"
      },
      "outputs": [],
      "source": [
        "# day08_trees_rf.py\n",
        "# Run from project root: python day08_trees_rf.py\n",
        "# Requires: pandas, numpy, scikit-learn, matplotlib, seaborn, joblib\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
        "import joblib\n",
        "\n",
        "OUT = Path(\"day08\"); OUT.mkdir(exist_ok=True)\n",
        "ASSETS = OUT / \"assets\"; ASSETS.mkdir(exist_ok=True)\n",
        "\n",
        "# -----------------------\n",
        "# 0) Load data (use best processed file if available)\n",
        "# -----------------------\n",
        "candidates = [\n",
        "    Path(\"day05/day05_titanic_feat.csv\"),\n",
        "    Path(\"day05_titanic_feat.csv\"),\n",
        "    Path(\"day02/day02_titanic_clean.csv\"),\n",
        "    Path(\"day02/day02_titanic_preserved.csv\"),\n",
        "    Path(\"train.csv\")\n",
        "]\n",
        "data = None\n",
        "for p in candidates:\n",
        "    if p.exists():\n",
        "        print(\"Loading:\", p)\n",
        "        data = pd.read_csv(p)\n",
        "        break\n",
        "if data is None:\n",
        "    raise FileNotFoundError(\"No input CSV found. Put day05_titanic_feat.csv or day02_titanic_clean.csv or train.csv in the project.\")\n",
        "\n",
        "# Ensure target exists\n",
        "if 'Survived' not in data.columns:\n",
        "    raise KeyError(\"'Survived' column not found in loaded data.\")\n",
        "\n",
        "# -----------------------\n",
        "# 1) Prepare X, y (simple safe preprocessing)\n",
        "# -----------------------\n",
        "df = data.copy()\n",
        "# Drop obviously useless columns if present\n",
        "for c in ['PassengerId','Ticket','Cabin','Name']:\n",
        "    if c in df.columns: df.drop(columns=[c], inplace=True)\n",
        "\n",
        "# If Sex is still string, convert\n",
        "if 'Sex' in df.columns and df['Sex'].dtype == object:\n",
        "    df['Sex'] = (df['Sex'].str.lower().str.startswith('m')).astype(int)\n",
        "\n",
        "# Fill Age/Fare if any missing\n",
        "if 'Age' in df.columns:\n",
        "    df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
        "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "if 'Fare' in df.columns:\n",
        "    df['Fare'] = pd.to_numeric(df['Fare'], errors='coerce')\n",
        "    df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
        "\n",
        "# One-hot encode any leftover categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
        "cat_cols = [c for c in cat_cols if c != 'Survived']\n",
        "if cat_cols:\n",
        "    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
        "\n",
        "X = df.drop(columns=['Survived'])\n",
        "y = df['Survived']\n",
        "\n",
        "# Train/test split (we'll keep a holdout test set)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Helper to evaluate and save plots\n",
        "def evaluate_and_plot(name, model, X_test, y_test, prefix):\n",
        "    y_pred = model.predict(X_test)\n",
        "    proba = model.predict_proba(X_test)[:,1] if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
        "        \"precision\": float(precision_score(y_test, y_pred)),\n",
        "        \"recall\": float(recall_score(y_test, y_pred)),\n",
        "        \"f1\": float(f1_score(y_test, y_pred)),\n",
        "        \"roc_auc\": float(roc_auc_score(y_test, proba)) if proba is not None else None\n",
        "    }\n",
        "    print(f\"\\n== {name} metrics:\", metrics)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(4,3))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"{name} Confusion\")\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ASSETS / f\"{prefix}_confusion.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # ROC curve\n",
        "    if proba is not None:\n",
        "        fpr, tpr, _ = roc_curve(y_test, proba)\n",
        "        plt.figure(figsize=(5,4))\n",
        "        plt.plot(fpr, tpr, label=f\"AUC={metrics['roc_auc']:.3f}\")\n",
        "        plt.plot([0,1],[0,1],'--',color='gray')\n",
        "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"{name} ROC\")\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(ASSETS / f\"{prefix}_roc.png\")\n",
        "        plt.close()\n",
        "\n",
        "    return metrics\n",
        "\n",
        "results = {}\n",
        "\n",
        "# -----------------------\n",
        "# 2) Decision Tree baseline\n",
        "# -----------------------\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "joblib.dump(dt, ASSETS / \"dt_baseline.joblib\")\n",
        "results['decision_tree_baseline'] = evaluate_and_plot(\"DecisionTree (baseline)\", dt, X_test, y_test, \"dt_baseline\")\n",
        "\n",
        "# Optional: visualize small tree (only if feature count small)\n",
        "try:\n",
        "    plt.figure(figsize=(12,8))\n",
        "    plot_tree(dt, max_depth=3, fontsize=8, feature_names=X.columns, class_names=['0','1'], filled=True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ASSETS/\"dt_tree_plot.png\")\n",
        "    plt.close()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# -----------------------\n",
        "# 3) Random Forest baseline\n",
        "# -----------------------\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "joblib.dump(rf, ASSETS / \"rf_baseline.joblib\")\n",
        "results['random_forest_baseline'] = evaluate_and_plot(\"RandomForest (baseline)\", rf, X_test, y_test, \"rf_baseline\")\n",
        "\n",
        "# Feature importances (top 20)\n",
        "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "plt.figure(figsize=(6,8))\n",
        "sns.barplot(x=importances.values[:20], y=importances.index[:20])\n",
        "plt.title(\"RF Top 20 Feature Importances\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(ASSETS/\"rf_feature_importances.png\")\n",
        "plt.close()\n",
        "\n",
        "# -----------------------\n",
        "# 4) Quick GridSearch (small) for RF (keeps runtime modest)\n",
        "# -----------------------\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [4, 6, None],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"]\n",
        "}\n",
        "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "gs = GridSearchCV(RandomForestClassifier(random_state=42, n_jobs=-1), param_grid, cv=cv, scoring='f1', n_jobs=-1, verbose=1)\n",
        "gs.fit(X_train, y_train)\n",
        "best_rf = gs.best_estimator_\n",
        "joblib.dump(best_rf, ASSETS/\"rf_best_grid.joblib\")\n",
        "results['random_forest_grid'] = {\n",
        "    'best_params': gs.best_params_,\n",
        "    'cv_best_score': float(gs.best_score_)\n",
        "}\n",
        "# evaluate on test\n",
        "results['random_forest_grid']['test_metrics'] = evaluate_and_plot(\"RandomForest (tuned)\", best_rf, X_test, y_test, \"rf_tuned\")\n",
        "\n",
        "# -----------------------\n",
        "# 5) Save results summary\n",
        "# -----------------------\n",
        "with open(OUT/\"day08_results.json\",\"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved results to\", OUT, \"assets to\", ASSETS)\n",
        "print(\"Summary:\", results)\n"
      ]
    }
  ]
}
